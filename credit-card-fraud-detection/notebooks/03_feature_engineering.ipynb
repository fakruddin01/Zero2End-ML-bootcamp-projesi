{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 03 - Feature Engineering\n",
                "\n",
                "Bu notebook'ta feature engineering ve class balancing yapacağız.\n",
                "\n",
                "## Hedefler:\n",
                "- Yeni feature'lar oluşturmak\n",
                "- Feature selection yapmak\n",
                "- SMOTE ile class balancing\n",
                "- İyileştirilmiş model performansı"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import classification_report, roc_auc_score\n",
                "from imblearn.over_sampling import SMOTE\n",
                "import plotly.graph_objects as go\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"✅ Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load and Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\n",
                "df = pd.read_csv('../data/creditcard.csv')\n",
                "\n",
                "# Separate features and target\n",
                "X = df.drop('Class', axis=1)\n",
                "y = df['Class']\n",
                "\n",
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Train set: {X_train.shape}\")\n",
                "print(f\"Test set: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create new features\n",
                "def create_features(df):\n",
                "    df_new = df.copy()\n",
                "    \n",
                "    # Time-based features\n",
                "    df_new['Hour'] = (df_new['Time'] / 3600) % 24\n",
                "    df_new['Day'] = (df_new['Time'] / 86400).astype(int)\n",
                "    \n",
                "    # Amount-based features\n",
                "    df_new['Amount_log'] = np.log1p(df_new['Amount'])\n",
                "    \n",
                "    # Interaction features (sample)\n",
                "    df_new['V1_V2'] = df_new['V1'] * df_new['V2']\n",
                "    df_new['V1_V3'] = df_new['V1'] * df_new['V3']\n",
                "    \n",
                "    return df_new\n",
                "\n",
                "X_train_fe = create_features(X_train)\n",
                "X_test_fe = create_features(X_test)\n",
                "\n",
                "print(f\"New feature count: {X_train_fe.shape[1]}\")\n",
                "print(f\"Added features: {set(X_train_fe.columns) - set(X_train.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Feature Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scale all features\n",
                "scaler = StandardScaler()\n",
                "\n",
                "X_train_scaled = pd.DataFrame(\n",
                "    scaler.fit_transform(X_train_fe),\n",
                "    columns=X_train_fe.columns,\n",
                "    index=X_train_fe.index\n",
                ")\n",
                "\n",
                "X_test_scaled = pd.DataFrame(\n",
                "    scaler.transform(X_test_fe),\n",
                "    columns=X_test_fe.columns,\n",
                "    index=X_test_fe.index\n",
                ")\n",
                "\n",
                "print(\"✅ Features scaled\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Handle Class Imbalance with SMOTE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check class distribution before SMOTE\n",
                "print(\"Before SMOTE:\")\n",
                "print(f\"Class 0: {(y_train == 0).sum()}\")\n",
                "print(f\"Class 1: {(y_train == 1).sum()}\")\n",
                "print(f\"Ratio: 1:{(y_train == 0).sum() / (y_train == 1).sum():.0f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply SMOTE\n",
                "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
                "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
                "\n",
                "print(\"\\nAfter SMOTE:\")\n",
                "print(f\"Class 0: {(y_train_smote == 0).sum()}\")\n",
                "print(f\"Class 1: {(y_train_smote == 1).sum()}\")\n",
                "print(f\"Ratio: 1:{(y_train_smote == 0).sum() / (y_train_smote == 1).sum():.1f}\")\n",
                "print(f\"\\nNew training set size: {X_train_smote.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize class distribution\n",
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Bar(\n",
                "    name='Before SMOTE',\n",
                "    x=['Normal', 'Fraud'],\n",
                "    y=[(y_train == 0).sum(), (y_train == 1).sum()],\n",
                "    marker_color='lightblue'\n",
                "))\n",
                "\n",
                "fig.add_trace(go.Bar(\n",
                "    name='After SMOTE',\n",
                "    x=['Normal', 'Fraud'],\n",
                "    y=[(y_train_smote == 0).sum(), (y_train_smote == 1).sum()],\n",
                "    marker_color='darkblue'\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title='Class Distribution: Before vs After SMOTE',\n",
                "    barmode='group',\n",
                "    height=500\n",
                ")\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train Model with Engineered Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train model with SMOTE data\n",
                "model_fe = LogisticRegression(random_state=42, max_iter=1000)\n",
                "model_fe.fit(X_train_smote, y_train_smote)\n",
                "\n",
                "print(\"✅ Model trained with feature engineering and SMOTE\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluate Improved Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions\n",
                "y_pred = model_fe.predict(X_test_scaled)\n",
                "y_pred_proba = model_fe.predict_proba(X_test_scaled)[:, 1]\n",
                "\n",
                "# Metrics\n",
                "print(\"Classification Report:\")\n",
                "print(classification_report(y_test, y_pred, target_names=['Normal', 'Fraud']))\n",
                "\n",
                "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Compare with Baseline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train baseline for comparison\n",
                "X_train_base_scaled = pd.DataFrame(\n",
                "    scaler.fit_transform(X_train),\n",
                "    columns=X_train.columns\n",
                ")\n",
                "X_test_base_scaled = pd.DataFrame(\n",
                "    scaler.transform(X_test),\n",
                "    columns=X_test.columns\n",
                ")\n",
                "\n",
                "baseline = LogisticRegression(random_state=42, max_iter=1000)\n",
                "baseline.fit(X_train_base_scaled, y_train)\n",
                "baseline_proba = baseline.predict_proba(X_test_base_scaled)[:, 1]\n",
                "baseline_auc = roc_auc_score(y_test, baseline_proba)\n",
                "\n",
                "print(\"Performance Comparison:\")\n",
                "print(f\"Baseline ROC-AUC: {baseline_auc:.4f}\")\n",
                "print(f\"Feature Engineered ROC-AUC: {roc_auc:.4f}\")\n",
                "print(f\"Improvement: {((roc_auc - baseline_auc) / baseline_auc * 100):.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Summary\n",
                "\n",
                "### Feature Engineering Results:\n",
                "- Created new time-based and amount-based features\n",
                "- Applied SMOTE for class balancing\n",
                "- Improved model performance\n",
                "\n",
                "### Next Steps:\n",
                "1. Try different models (Random Forest, XGBoost)\n",
                "2. Hyperparameter tuning\n",
                "3. Advanced feature selection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"✅ Feature engineering completed!\")\n",
                "print(\"\\nNext: Run 04_model_optimization.ipynb\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}