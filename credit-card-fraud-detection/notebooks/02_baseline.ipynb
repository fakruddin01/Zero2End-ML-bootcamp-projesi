{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 - Baseline Model\n",
                "\n",
                "Bu notebook'ta basit bir baseline model oluşturacağız.\n",
                "\n",
                "## Hedefler:\n",
                "- Veriyi train/test olarak ayırmak\n",
                "- Basit bir Logistic Regression modeli eğitmek\n",
                "- Model performansını değerlendirmek\n",
                "- Baseline metrikler oluşturmak"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import (\n",
                "    classification_report, \n",
                "    confusion_matrix, \n",
                "    roc_auc_score,\n",
                "    roc_curve,\n",
                "    precision_recall_curve,\n",
                "    average_precision_score\n",
                ")\n",
                "import plotly.graph_objects as go\n",
                "from plotly.subplots import make_subplots\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"✅ Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load dataset\n",
                "df = pd.read_csv('../data/creditcard.csv')\n",
                "\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "print(f\"Fraud cases: {df['Class'].sum()} ({df['Class'].mean()*100:.4f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Separate features and target\n",
                "X = df.drop('Class', axis=1)\n",
                "y = df['Class']\n",
                "\n",
                "print(f\"Features shape: {X.shape}\")\n",
                "print(f\"Target shape: {y.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, \n",
                "    test_size=0.2, \n",
                "    random_state=42,\n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Train set: {X_train.shape}\")\n",
                "print(f\"Test set: {X_test.shape}\")\n",
                "print(f\"\\nTrain fraud rate: {y_train.mean()*100:.4f}%\")\n",
                "print(f\"Test fraud rate: {y_test.mean()*100:.4f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Scale features\n",
                "scaler = StandardScaler()\n",
                "\n",
                "# Scale Time and Amount\n",
                "X_train_scaled = X_train.copy()\n",
                "X_test_scaled = X_test.copy()\n",
                "\n",
                "X_train_scaled[['Time', 'Amount']] = scaler.fit_transform(X_train[['Time', 'Amount']])\n",
                "X_test_scaled[['Time', 'Amount']] = scaler.transform(X_test[['Time', 'Amount']])\n",
                "\n",
                "print(\"✅ Features scaled\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train Baseline Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize model\n",
                "baseline_model = LogisticRegression(\n",
                "    random_state=42,\n",
                "    max_iter=1000,\n",
                "    solver='liblinear'\n",
                ")\n",
                "\n",
                "# Train model\n",
                "print(\"Training baseline model...\")\n",
                "baseline_model.fit(X_train_scaled, y_train)\n",
                "print(\"✅ Model trained\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Make Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions\n",
                "y_pred = baseline_model.predict(X_test_scaled)\n",
                "y_pred_proba = baseline_model.predict_proba(X_test_scaled)[:, 1]\n",
                "\n",
                "print(f\"Predictions made: {len(y_pred)}\")\n",
                "print(f\"Predicted frauds: {y_pred.sum()}\")\n",
                "print(f\"Actual frauds: {y_test.sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Classification report\n",
                "print(\"Classification Report:\")\n",
                "print(classification_report(y_test, y_pred, target_names=['Normal', 'Fraud']))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "fig = go.Figure(data=go.Heatmap(\n",
                "    z=cm,\n",
                "    x=['Predicted Normal', 'Predicted Fraud'],\n",
                "    y=['Actual Normal', 'Actual Fraud'],\n",
                "    text=cm,\n",
                "    texttemplate='%{text}',\n",
                "    colorscale='Blues'\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title='Confusion Matrix',\n",
                "    xaxis_title='Predicted',\n",
                "    yaxis_title='Actual',\n",
                "    height=500\n",
                ")\n",
                "fig.show()\n",
                "\n",
                "print(f\"\\nTrue Negatives: {cm[0,0]}\")\n",
                "print(f\"False Positives: {cm[0,1]}\")\n",
                "print(f\"False Negatives: {cm[1,0]}\")\n",
                "print(f\"True Positives: {cm[1,1]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC-AUC Score\n",
                "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
                "print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
                "\n",
                "# Average Precision Score\n",
                "avg_precision = average_precision_score(y_test, y_pred_proba)\n",
                "print(f\"Average Precision Score: {avg_precision:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curve\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
                "\n",
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=fpr, y=tpr,\n",
                "    mode='lines',\n",
                "    name=f'ROC Curve (AUC = {roc_auc:.4f})',\n",
                "    line=dict(color='blue', width=2)\n",
                "))\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=[0, 1], y=[0, 1],\n",
                "    mode='lines',\n",
                "    name='Random Classifier',\n",
                "    line=dict(color='red', width=2, dash='dash')\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title='ROC Curve',\n",
                "    xaxis_title='False Positive Rate',\n",
                "    yaxis_title='True Positive Rate',\n",
                "    height=500\n",
                ")\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Precision-Recall Curve\n",
                "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
                "\n",
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Scatter(\n",
                "    x=recall, y=precision,\n",
                "    mode='lines',\n",
                "    name=f'PR Curve (AP = {avg_precision:.4f})',\n",
                "    line=dict(color='green', width=2)\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title='Precision-Recall Curve',\n",
                "    xaxis_title='Recall',\n",
                "    yaxis_title='Precision',\n",
                "    height=500\n",
                ")\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get feature importance (coefficients)\n",
                "feature_importance = pd.DataFrame({\n",
                "    'feature': X_train.columns,\n",
                "    'coefficient': baseline_model.coef_[0]\n",
                "}).sort_values('coefficient', key=abs, ascending=False)\n",
                "\n",
                "print(\"Top 10 Most Important Features:\")\n",
                "print(feature_importance.head(10))\n",
                "\n",
                "# Visualize\n",
                "fig = go.Figure()\n",
                "\n",
                "fig.add_trace(go.Bar(\n",
                "    x=feature_importance['feature'][:15],\n",
                "    y=feature_importance['coefficient'][:15],\n",
                "    marker_color=['red' if x < 0 else 'green' for x in feature_importance['coefficient'][:15]]\n",
                "))\n",
                "\n",
                "fig.update_layout(\n",
                "    title='Top 15 Feature Coefficients',\n",
                "    xaxis_title='Features',\n",
                "    yaxis_title='Coefficient',\n",
                "    height=500\n",
                ")\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Summary\n",
                "\n",
                "### Baseline Model Performance:\n",
                "- **Model**: Logistic Regression\n",
                "- **ROC-AUC**: Check output above\n",
                "- **Average Precision**: Check output above\n",
                "\n",
                "### Key Observations:\n",
                "1. Model performs reasonably well despite class imbalance\n",
                "2. Some features show strong predictive power\n",
                "3. There's room for improvement with:\n",
                "   - Feature engineering\n",
                "   - Handling class imbalance (SMOTE)\n",
                "   - Trying different models\n",
                "   - Hyperparameter tuning\n",
                "\n",
                "### Next Steps:\n",
                "1. Feature engineering (03_feature_engineering.ipynb)\n",
                "2. Apply SMOTE for class balancing\n",
                "3. Try more complex models\n",
                "4. Optimize hyperparameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"✅ Baseline model completed successfully!\")\n",
                "print(f\"\\nBaseline ROC-AUC: {roc_auc:.4f}\")\n",
                "print(\"\\nNext: Run 03_feature_engineering.ipynb\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}