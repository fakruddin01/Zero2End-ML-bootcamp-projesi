{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 06 - Final Pipeline\n",
                "\n",
                "Bu notebook'ta tÃ¼m pipeline'Ä± birleÅŸtirip final modeli kaydedeceÄŸiz.\n",
                "\n",
                "## Hedefler:\n",
                "- TÃ¼m preprocessing ve model adÄ±mlarÄ±nÄ± birleÅŸtirmek\n",
                "- Final modeli eÄŸitmek\n",
                "- Modeli ve scaler'Ä± kaydetmek\n",
                "- Deployment iÃ§in hazÄ±rlamak"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import sys\n",
                "sys.path.append('../src')\n",
                "\n",
                "from pipeline import FraudDetectionPipeline\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "import pandas as pd\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"âœ… Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Initialize Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create pipeline instance\n",
                "pipeline = FraudDetectionPipeline()\n",
                "\n",
                "print(\"Pipeline initialized\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load and Explore Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "df = pipeline.load_data()\n",
                "\n",
                "print(f\"Dataset loaded: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Explore data\n",
                "exploration = pipeline.explore_data()\n",
                "\n",
                "print(\"Data Exploration:\")\n",
                "print(f\"Shape: {exploration['shape']}\")\n",
                "print(f\"Class distribution: {exploration['class_distribution']}\")\n",
                "print(f\"Fraud percentage: {exploration['fraud_percentage']:.4f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Preprocess Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocess with SMOTE\n",
                "X_train, X_test, y_train, y_test = pipeline.preprocess_data(apply_smote=True)\n",
                "\n",
                "print(f\"Training set: {X_train.shape}\")\n",
                "print(f\"Test set: {X_test.shape}\")\n",
                "print(f\"Class distribution after SMOTE: {pd.Series(y_train).value_counts().to_dict()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define best model (from optimization results)\n",
                "best_model = RandomForestClassifier(\n",
                "    n_estimators=200,\n",
                "    max_depth=20,\n",
                "    min_samples_split=5,\n",
                "    min_samples_leaf=2,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "# Train\n",
                "print(\"Training final model...\")\n",
                "pipeline.train_model(model=best_model)\n",
                "print(\"âœ… Model trained\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluate Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate\n",
                "evaluation = pipeline.evaluate_model()\n",
                "\n",
                "print(\"\\nModel Evaluation:\")\n",
                "print(f\"ROC-AUC Score: {evaluation['roc_auc_score']:.4f}\")\n",
                "print(\"\\nClassification Report:\")\n",
                "print(pd.DataFrame(evaluation['classification_report']).transpose())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model and scaler\n",
                "pipeline.save_model()\n",
                "\n",
                "print(\"âœ… Model and scaler saved successfully!\")\n",
                "print(\"\\nModel files:\")\n",
                "print(\"  â€¢ ../models/fraud_detection_model.pkl\")\n",
                "print(\"  â€¢ ../models/scaler.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Test Saved Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test loading and using the saved model\n",
                "from inference import FraudDetector\n",
                "\n",
                "# Initialize detector\n",
                "detector = FraudDetector()\n",
                "detector.load_model()\n",
                "\n",
                "# Create sample transaction\n",
                "sample_transaction = {\n",
                "    'Time': 0,\n",
                "    'Amount': 149.62,\n",
                "    'V1': -1.359807,\n",
                "    'V2': -0.072781,\n",
                "    'V3': 2.536347,\n",
                "    'V4': 1.378155,\n",
                "    'V5': -0.338321,\n",
                "    'V6': 0.462388,\n",
                "    'V7': 0.239599,\n",
                "    'V8': 0.098698,\n",
                "    'V9': 0.363787,\n",
                "    'V10': 0.090794,\n",
                "    'V11': -0.551600,\n",
                "    'V12': -0.617801,\n",
                "    'V13': -0.991390,\n",
                "    'V14': -0.311169,\n",
                "    'V15': 1.468177,\n",
                "    'V16': -0.470401,\n",
                "    'V17': 0.207971,\n",
                "    'V18': 0.025791,\n",
                "    'V19': 0.403993,\n",
                "    'V20': 0.251412,\n",
                "    'V21': -0.018307,\n",
                "    'V22': 0.277838,\n",
                "    'V23': -0.110474,\n",
                "    'V24': 0.066928,\n",
                "    'V25': 0.128539,\n",
                "    'V26': -0.189115,\n",
                "    'V27': 0.133558,\n",
                "    'V28': -0.021053\n",
                "}\n",
                "\n",
                "# Make prediction\n",
                "result = detector.predict_with_details(sample_transaction)[0]\n",
                "\n",
                "print(\"\\nSample Prediction Test:\")\n",
                "print(f\"Prediction: {result['prediction_label']}\")\n",
                "print(f\"Fraud Probability: {result['fraud_probability']:.4f}\")\n",
                "print(f\"Risk Level: {result['risk_level']}\")\n",
                "print(f\"Confidence: {result['confidence']:.4f}\")\n",
                "\n",
                "print(\"\\nâœ… Model inference working correctly!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Final Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary = f\"\"\"\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "           FINAL PIPELINE SUMMARY\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\n",
                "âœ… Pipeline Steps Completed:\n",
                "  1. Data Loading and Exploration\n",
                "  2. Data Preprocessing and Scaling\n",
                "  3. SMOTE for Class Balancing\n",
                "  4. Model Training (Random Forest)\n",
                "  5. Model Evaluation\n",
                "  6. Model and Scaler Saved\n",
                "\n",
                "ğŸ“Š Final Model Performance:\n",
                "  â€¢ ROC-AUC Score: {evaluation['roc_auc_score']:.4f}\n",
                "  â€¢ Model Type: Random Forest Classifier\n",
                "  â€¢ Features: 30 (Time, Amount, V1-V28)\n",
                "\n",
                "ğŸ’¾ Saved Files:\n",
                "  â€¢ Model: ../models/fraud_detection_model.pkl\n",
                "  â€¢ Scaler: ../models/scaler.pkl\n",
                "\n",
                "ğŸš€ Ready for Deployment:\n",
                "  â€¢ Streamlit App: streamlit run ../src/app.py\n",
                "  â€¢ Inference Module: ../src/inference.py\n",
                "\n",
                "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
                "\"\"\"\n",
                "\n",
                "print(summary)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Next Steps\n",
                "\n",
                "### Deployment:\n",
                "1. **Run Streamlit App**:\n",
                "   ```bash\n",
                "   streamlit run ../src/app.py\n",
                "   ```\n",
                "\n",
                "2. **Use Inference Module**:\n",
                "   ```python\n",
                "   from inference import predict_fraud\n",
                "   results = predict_fraud(transaction_data)\n",
                "   ```\n",
                "\n",
                "3. **Deploy to Cloud**:\n",
                "   - Streamlit Cloud\n",
                "   - Heroku\n",
                "   - AWS/GCP/Azure\n",
                "\n",
                "### Further Improvements:\n",
                "- Experiment with deep learning models\n",
                "- Implement real-time monitoring\n",
                "- Add model versioning\n",
                "- Create API endpoints\n",
                "- Add automated retraining pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ğŸ‰ CONGRATULATIONS! ğŸ‰\")\n",
                "print(\"=\"*60)\n",
                "print(\"\\nYou have successfully completed the entire ML pipeline!\")\n",
                "print(\"\\nThe model is now ready for deployment.\")\n",
                "print(\"\\nTo run the Streamlit app:\")\n",
                "print(\"  cd ../src\")\n",
                "print(\"  streamlit run app.py\")\n",
                "print(\"\\n\" + \"=\"*60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}